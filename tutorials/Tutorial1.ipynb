{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Template-Matching\n",
    "\n",
    "This tutorial gives an overview of the different ways to use multiple template matching for object recognition.\n",
    "More documentation is available in the [wiki](https://github.com/LauLauThom/MultiTemplateMatching/wiki) section of the repository.\n",
    "\n",
    "## Citations\n",
    "If you use this implementation for your research, please cite:\n",
    "\n",
    "*Multi-Template Matching: a versatile tool for object-localization in microscopy images;*  \n",
    "Laurent SV Thomas, Jochen Gehrig\n",
    "bioRxiv 619338; doi: https://doi.org/10.1101/619338\n",
    "\n",
    "## Let's code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'NMS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-df4aa9738839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1st import the package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mMTM\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatchTemplates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrawBoxesOnRGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoins\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\Py3CV\\lib\\site-packages\\MTM\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m    \u001b[1;32mimport\u001b[0m \u001b[0mfind_peaks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mNMS\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'NMS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'NMS'"
     ]
    }
   ],
   "source": [
    "# 1st import the package\n",
    "from MTM import matchTemplates, drawBoxesOnRGB\n",
    "\n",
    "import cv2\n",
    "from skimage.data import coins\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open some image of coins from scikit-image, we will showcase the multi-template matching for the detection of the coin locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = coins()\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some template image to search in the image.  \n",
    "We can simply crop some coins from the image.  \n",
    "__NB : templates are always rectangular (there are image matrices). And thus the predicted locations are always rectangular too !__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallCoin = coins()[37:37+38, 80:80+41] \n",
    "plt.imshow(smallCoin, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the `matchTemplates` function of the package MultiTemplateMatching.\n",
    "The function has the following signature\n",
    "`matchTemplates(listTemplates, image, method=cv2.TM_CCOEFF_NORMED, N_object=float(\"inf\"), score_threshold=0.5, maxOverlap=0.25)`\n",
    "\n",
    "- __listTemplates__   : list containing tuples like (\"label\", image) for each template that should be searched\n",
    "- __image__           : this is the image in which the search is performed, in this case the image with the coins\n",
    "- __method__          : one of OpenCV method for the computation of the correlation map (normalised difference, correlation...)\n",
    "- __N_object__        : optionnal parameter, if set the function returns the N_object detections of highest score that do not overlap above the threshold\n",
    "- __score_threshold__ : when performing multiple object detections, this is the minimal/maximal score for each detection when using respectively correlation/difference score\n",
    "- __maxOverlap__      : Maximal ratio for the Intersection Over Union between overlapping detections. If above the threshold, the lower score bounding box is discarded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st format the template into a list of tuple (label, templateImage)\n",
    "listTemplate = [('small', smallCoin)]\n",
    "\n",
    "# Then call the function matchTemplates (here a single template)\n",
    "listHit = matchTemplates(listTemplate, image, score_threshold=0.5, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the coins are nicely separated so we do not expect any overlap between the predicted coins locations ie `maxOverlap=0`.  \n",
    "For the score, we use a normalised cross-correlation `cv2.TM_CCOEFF_NORMED`, which is robust to illumination changes.  \n",
    "Such score ranges from 0 to 1 and a good score is close to 1. `score_threshold=0.5` is thus usually a safe value.\n",
    "\n",
    "Let's have a look at `listHit`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Found {} hits\".format( len(listHit) ) )\n",
    "for hit in listHit: print(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, listHit stores each possible location of the template as a dictionary containing:\n",
    "- the name of the template that yield the match\n",
    "- the coordinates of the bounding box (x, y, width, height)\n",
    "- the score for that detection  \n",
    "\n",
    "The first hit in the lsit has a score of 1 and is the coin that is used as template.\n",
    "\n",
    "We can then represent the detections as bounding boxes overlaid on the image, with a tag for the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overlay = drawBoxesOnRGB(image, listHit, showLabel=True)\n",
    "plt.imshow(Overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good already but we dont catch some of the small coins.  \n",
    "Let's reduce the score threshold to be more permissive e.g. `score_threshold = 0.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listHit = matchTemplates(listTemplate, image, score_threshold=0.4, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0)\n",
    "Overlay = drawBoxesOnRGB(image, listHit, showLabel=True)\n",
    "plt.imshow(Overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it !  \n",
    "What if now we would like to do better and somehow differentiate between small and large coins...  \n",
    "The function matchTemplates allow to use several templates, and yields the best detections for each location in the image.  \n",
    "Let's crop one of the big coin to use as a second template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeCoin = coins()[14:14+59,302:302+65]\n",
    "plt.figure(0)\n",
    "plt.imshow(smallCoin, cmap=\"gray\")\n",
    "plt.figure(1)\n",
    "plt.imshow(largeCoin, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we pack the templates in a list of tuples in the form `(label, template)`.    \n",
    "Before calling the function `matchTemplates` and displaying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listTemplate = [(\"small\", smallCoin), (\"large\", largeCoin)]\n",
    "listHit = matchTemplates(listTemplate, image, score_threshold=0.4, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0)\n",
    "Overlay = drawBoxesOnRGB(image, listHit, showLabel=True)\n",
    "plt.imshow(Overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila !  \n",
    "Using several templates can be used to increase the chance to catch your object if it appears with different perspectives, or to perform classification of the detections using different templates as \"classes\".  \n",
    "However, the more templates the longer the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
